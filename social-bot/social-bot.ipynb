{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article(BaseModel):\n",
    "    title: str\n",
    "    link: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacker News RSS\n",
    "URL = \"https://news.ycombinator.com/rss\"\n",
    "\n",
    "\n",
    "def find_articles() -> list[Article]:\n",
    "    \"\"\"Finds a top AI-related article from HackerNews\"\"\"\n",
    "    rss_response = requests.get(URL)\n",
    "    data = xmltodict.parse(rss_response.content)\n",
    "\n",
    "    # Find all articles with these keywords\n",
    "    keywords = {\n",
    "        \"ai\",\n",
    "        \"genai\",\n",
    "        \"lightning\",\n",
    "        \"pytorch\",\n",
    "        \"llm\",\n",
    "        \"llms\",\n",
    "        \"ml\",\n",
    "        \"rag\",\n",
    "        \"nlp\",\n",
    "        \"openai\",\n",
    "        \"gemma\",\n",
    "        \"anthropic\",\n",
    "    }\n",
    "\n",
    "    articles = []\n",
    "    for item in data[\"rss\"][\"channel\"][\"item\"]:\n",
    "        title = item[\"title\"].lower()\n",
    "        link = item[\"link\"]\n",
    "\n",
    "        # Skip articles from Hacker News, Show HN, and job postings\n",
    "        if (\n",
    "            link.startswith(\"https://news.ycombinator.com\")\n",
    "            or title.startswith(\"Show HN\")\n",
    "            or \"is hiring\" in title\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Check if any of the keywords are in the title\n",
    "        if any(word in title.split(\" \") for word in keywords):\n",
    "            articles.append(Article(title=title, link=link))\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm.c ‚Äì llm training in simple, pure c/cuda - https://github.com/karpathy/llm.c\n",
      "hello olmo: a truly open llm - https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222?gi=760105621962\n",
      "after ai beat them, professional go players got better and more creative - https://www.henrikkarlsson.xyz/p/go\n"
     ]
    }
   ],
   "source": [
    "articles = find_articles()\n",
    "for article in articles:\n",
    "    print(f\"{article.title} - {article.link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlePage(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article_page(url: str):\n",
    "    \"\"\"Fetches the article page\"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # wait a few seconds for ajax content to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # grabs all the visible content of the page\n",
    "    content = driver.find_element(by=By.CSS_SELECTOR, value=\"body\").text\n",
    "\n",
    "    # metadata\n",
    "    head_html = driver.execute_script(\"return document.head.innerHTML;\")\n",
    "    head_soup = BeautifulSoup(head_html, \"html.parser\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # grab seo metadata for title and description\n",
    "    title = head_soup.title.text\n",
    "\n",
    "    desc_tag = head_soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "\n",
    "    if desc_tag is None:\n",
    "        # Fall back to open graph tags\n",
    "        desc_tag = head_soup.find(\"meta\", attrs={\"name\": \"og:description\"})\n",
    "\n",
    "    description = \"\"\n",
    "\n",
    "    if desc_tag is not None:\n",
    "        description = desc_tag[\"content\"]\n",
    "\n",
    "    return ArticlePage(title=title, description=description, content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "The content of an article is:\n",
    "\n",
    "{content}\n",
    "\n",
    "Write some commentary about about a key point of the article's contents and encourage the reader to check it out in a professinal tone for a Twitter post.\n",
    "The entire post should be two sentences. Use a couple emojis too.\n",
    "Respond with just the post, no additional commentary, no notes, no link.\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(base_url=\"https://api.together.xyz/v1\", model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "\n",
    "def generate_post(article: ArticlePage):\n",
    "    max_content_length = 7000\n",
    "    content = (\n",
    "        len(article.content) > max_content_length\n",
    "        and article.content[:max_content_length] + \"...\"\n",
    "        or article.content\n",
    "    )\n",
    "    output = chain.invoke({\"content\": article.content})\n",
    "    output = output.strip().strip('\"')\n",
    "    output = re.sub(r\"#\\w+\", \"\", output)    \n",
    "    output = re.sub(r\"\\s+\", \" \", output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from requests_oauthlib import OAuth1Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_twitter(post_content: str, url: str):\n",
    "    \"\"\"Posts the content to Twitter\"\"\"\n",
    "    oauth = OAuth1Session(\n",
    "        # \"Consumer Keys\" under \"Keys and Tokens\" in the developer console\n",
    "        os.environ.get(\"X_CONSUMER_KEY\"),\n",
    "        client_secret=os.environ.get(\"X_CONSUMER_SECRET\"),\n",
    "        # \"Access Token and Secret\" under \"Keys and Tokens\" in the developer console\n",
    "        resource_owner_key=os.environ.get(\"X_TOKEN\"),\n",
    "        resource_owner_secret=os.environ.get(\"X_SECRET\"),\n",
    "    )\n",
    "\n",
    "    response = oauth.post(\n",
    "        \"https://api.twitter.com/2/tweets\",\n",
    "        json={\"text\": f\"{post_content}\\n{url}\"},\n",
    "    )\n",
    "\n",
    "    if response.status_code != 201:\n",
    "        print(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = articles[2]\n",
    "article_page = fetch_article_page(article.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "Fascinating article on the impact of AI on professional Go players' improvement üéÆ‚úèÔ∏è. Over 60% of the improvement in human moves was attributed to moves that deviated from the AI's suggestions, indicating increased human creativity. Check it out! \n"
     ]
    }
   ],
   "source": [
    "post_content = generate_post(article_page)\n",
    "post_content\n",
    "print(len(post_content))\n",
    "print(post_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_twitter(post_content, article.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social-bot-JLXUEBYX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
